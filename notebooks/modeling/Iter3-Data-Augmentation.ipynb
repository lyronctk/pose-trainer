{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77fb58c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import itertools\n",
    "from typing import List, Tuple\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "from skimage.io import imread\n",
    "import time\n",
    "from ast import literal_eval\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from statistics import median, mean\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation, concatenate, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e46db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34f96def",
   "metadata": {},
   "source": [
    "# Parse and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8214bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936daa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (640, 360)\n",
    "IMAGE_EXAMPLE_SHAPE = TARGET_SIZE + (3,)\n",
    "\n",
    "LANDMARK_EXAMPLE_SHAPE = (39, )\n",
    "\n",
    "BASE_PATH = '/home/lancecotingkeh/aggregated/'\n",
    "LABEL_TO_ENCODING = {'proper': 0, 'crooked': 1, 'lockout': 2, 'rounded': 3, 'squat': 4}\n",
    "ENCODING_TO_LABEL = {v: k for k, v in LABEL_TO_ENCODING.items()}\n",
    "NUM_CLASSES = len(LABEL_TO_ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8a85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3e379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f2c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata = pd.read_csv('/home/lancecotingkeh/aggregated/pose_landmarks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a59a4d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_image_path</th>\n",
       "      <th>data_split</th>\n",
       "      <th>label</th>\n",
       "      <th>landmark_nose</th>\n",
       "      <th>landmark_left_shoulder</th>\n",
       "      <th>landmark_right_shoulder</th>\n",
       "      <th>landmark_left_elbow</th>\n",
       "      <th>landmark_right_elbow</th>\n",
       "      <th>landmark_left_wrist</th>\n",
       "      <th>landmark_right_wrist</th>\n",
       "      <th>landmark_left_hip</th>\n",
       "      <th>landmark_right_hip</th>\n",
       "      <th>landmark_left_knee</th>\n",
       "      <th>landmark_right_knee</th>\n",
       "      <th>landmark_left_ankle</th>\n",
       "      <th>landmark_right_ankle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5_lockout/lyron_deg135_take2/frame46.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>proper</td>\n",
       "      <td>(0.8408212661743164, 0.44535547494888306, -0.6...</td>\n",
       "      <td>(0.7523922920227051, 0.483453631401062, -0.080...</td>\n",
       "      <td>(0.59047532081604, 0.4363204836845398, -0.5876...</td>\n",
       "      <td>(0.7419312596321106, 0.6247938871383667, 0.025...</td>\n",
       "      <td>(0.5161336064338684, 0.5835246443748474, -0.57...</td>\n",
       "      <td>(0.7500355839729309, 0.7468990683555603, -0.06...</td>\n",
       "      <td>(0.5082715749740601, 0.7348905205726624, -0.60...</td>\n",
       "      <td>(0.4615359604358673, 0.5611119866371155, 0.148...</td>\n",
       "      <td>(0.34500354528427124, 0.5380272269248962, -0.1...</td>\n",
       "      <td>(0.701583981513977, 0.6245787739753723, -0.039...</td>\n",
       "      <td>(0.5147499442100525, 0.576558530330658, -0.833...</td>\n",
       "      <td>(0.6168646812438965, 0.8138770461082458, 0.163...</td>\n",
       "      <td>(0.4869398772716522, 0.7884341478347778, -0.77...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5_lockout/lyron_deg135_take2/frame203.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>proper</td>\n",
       "      <td>(0.8654815554618835, 0.4472369849681854, -0.59...</td>\n",
       "      <td>(0.7866912484169006, 0.5048587322235107, -0.12...</td>\n",
       "      <td>(0.6134108901023865, 0.4505915343761444, -0.55...</td>\n",
       "      <td>(0.7522295713424683, 0.6383607983589172, -0.09...</td>\n",
       "      <td>(0.5366990566253662, 0.5983656644821167, -0.55...</td>\n",
       "      <td>(0.7443258762359619, 0.7658225893974304, -0.16...</td>\n",
       "      <td>(0.5270508527755737, 0.7469443678855896, -0.51...</td>\n",
       "      <td>(0.49029654264450073, 0.565066397190094, 0.141...</td>\n",
       "      <td>(0.3752322196960449, 0.5404682159423828, -0.14...</td>\n",
       "      <td>(0.721193253993988, 0.6225733160972595, 0.0097...</td>\n",
       "      <td>(0.604214072227478, 0.5913941860198975, -0.544...</td>\n",
       "      <td>(0.6175094246864319, 0.7968677282333374, 0.155...</td>\n",
       "      <td>(0.4880143404006958, 0.7921530604362488, -0.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5_lockout/lyron_deg135_take2/frame207.jpg</td>\n",
       "      <td>train</td>\n",
       "      <td>proper</td>\n",
       "      <td>(0.8618521690368652, 0.42703595757484436, -0.5...</td>\n",
       "      <td>(0.7759232521057129, 0.48765045404434204, -0.0...</td>\n",
       "      <td>(0.6108279228210449, 0.43047401309013367, -0.4...</td>\n",
       "      <td>(0.7476211786270142, 0.6245181560516357, 0.032...</td>\n",
       "      <td>(0.526120126247406, 0.5700463652610779, -0.489...</td>\n",
       "      <td>(0.7355574369430542, 0.7427244186401367, -0.06...</td>\n",
       "      <td>(0.5221640467643738, 0.7184542417526245, -0.49...</td>\n",
       "      <td>(0.4879094958305359, 0.5496541261672974, 0.132...</td>\n",
       "      <td>(0.37393078207969666, 0.5203757286071777, -0.1...</td>\n",
       "      <td>(0.7107850313186646, 0.6180444359779358, 0.138...</td>\n",
       "      <td>(0.574447512626648, 0.5620325207710266, -0.697...</td>\n",
       "      <td>(0.5569970607757568, 0.7731618285179138, 0.340...</td>\n",
       "      <td>(0.47665083408355713, 0.7690679430961609, -0.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         relative_image_path data_split   label  \\\n",
       "0   5_lockout/lyron_deg135_take2/frame46.jpg      train  proper   \n",
       "1  5_lockout/lyron_deg135_take2/frame203.jpg      train  proper   \n",
       "2  5_lockout/lyron_deg135_take2/frame207.jpg      train  proper   \n",
       "\n",
       "                                       landmark_nose  \\\n",
       "0  (0.8408212661743164, 0.44535547494888306, -0.6...   \n",
       "1  (0.8654815554618835, 0.4472369849681854, -0.59...   \n",
       "2  (0.8618521690368652, 0.42703595757484436, -0.5...   \n",
       "\n",
       "                              landmark_left_shoulder  \\\n",
       "0  (0.7523922920227051, 0.483453631401062, -0.080...   \n",
       "1  (0.7866912484169006, 0.5048587322235107, -0.12...   \n",
       "2  (0.7759232521057129, 0.48765045404434204, -0.0...   \n",
       "\n",
       "                             landmark_right_shoulder  \\\n",
       "0  (0.59047532081604, 0.4363204836845398, -0.5876...   \n",
       "1  (0.6134108901023865, 0.4505915343761444, -0.55...   \n",
       "2  (0.6108279228210449, 0.43047401309013367, -0.4...   \n",
       "\n",
       "                                 landmark_left_elbow  \\\n",
       "0  (0.7419312596321106, 0.6247938871383667, 0.025...   \n",
       "1  (0.7522295713424683, 0.6383607983589172, -0.09...   \n",
       "2  (0.7476211786270142, 0.6245181560516357, 0.032...   \n",
       "\n",
       "                                landmark_right_elbow  \\\n",
       "0  (0.5161336064338684, 0.5835246443748474, -0.57...   \n",
       "1  (0.5366990566253662, 0.5983656644821167, -0.55...   \n",
       "2  (0.526120126247406, 0.5700463652610779, -0.489...   \n",
       "\n",
       "                                 landmark_left_wrist  \\\n",
       "0  (0.7500355839729309, 0.7468990683555603, -0.06...   \n",
       "1  (0.7443258762359619, 0.7658225893974304, -0.16...   \n",
       "2  (0.7355574369430542, 0.7427244186401367, -0.06...   \n",
       "\n",
       "                                landmark_right_wrist  \\\n",
       "0  (0.5082715749740601, 0.7348905205726624, -0.60...   \n",
       "1  (0.5270508527755737, 0.7469443678855896, -0.51...   \n",
       "2  (0.5221640467643738, 0.7184542417526245, -0.49...   \n",
       "\n",
       "                                   landmark_left_hip  \\\n",
       "0  (0.4615359604358673, 0.5611119866371155, 0.148...   \n",
       "1  (0.49029654264450073, 0.565066397190094, 0.141...   \n",
       "2  (0.4879094958305359, 0.5496541261672974, 0.132...   \n",
       "\n",
       "                                  landmark_right_hip  \\\n",
       "0  (0.34500354528427124, 0.5380272269248962, -0.1...   \n",
       "1  (0.3752322196960449, 0.5404682159423828, -0.14...   \n",
       "2  (0.37393078207969666, 0.5203757286071777, -0.1...   \n",
       "\n",
       "                                  landmark_left_knee  \\\n",
       "0  (0.701583981513977, 0.6245787739753723, -0.039...   \n",
       "1  (0.721193253993988, 0.6225733160972595, 0.0097...   \n",
       "2  (0.7107850313186646, 0.6180444359779358, 0.138...   \n",
       "\n",
       "                                 landmark_right_knee  \\\n",
       "0  (0.5147499442100525, 0.576558530330658, -0.833...   \n",
       "1  (0.604214072227478, 0.5913941860198975, -0.544...   \n",
       "2  (0.574447512626648, 0.5620325207710266, -0.697...   \n",
       "\n",
       "                                 landmark_left_ankle  \\\n",
       "0  (0.6168646812438965, 0.8138770461082458, 0.163...   \n",
       "1  (0.6175094246864319, 0.7968677282333374, 0.155...   \n",
       "2  (0.5569970607757568, 0.7731618285179138, 0.340...   \n",
       "\n",
       "                                landmark_right_ankle  \n",
       "0  (0.4869398772716522, 0.7884341478347778, -0.77...  \n",
       "1  (0.4880143404006958, 0.7921530604362488, -0.41...  \n",
       "2  (0.47665083408355713, 0.7690679430961609, -0.6...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2d46f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['landmark_nose',\n",
       " 'landmark_left_shoulder',\n",
       " 'landmark_right_shoulder',\n",
       " 'landmark_left_elbow',\n",
       " 'landmark_right_elbow',\n",
       " 'landmark_left_wrist',\n",
       " 'landmark_right_wrist',\n",
       " 'landmark_left_hip',\n",
       " 'landmark_right_hip',\n",
       " 'landmark_left_knee',\n",
       " 'landmark_right_knee',\n",
       " 'landmark_left_ankle',\n",
       " 'landmark_right_ankle']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmark_columns = [col for col in df_metadata if col.startswith('landmark_')]\n",
    "landmark_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8307ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_imgs(image_paths: List[str]) -> np.ndarray:\n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        img = load_img(image_path, target_size=TARGET_SIZE)        \n",
    "        np_img = np.asarray(img)\n",
    "\n",
    "        assert np_img.shape == IMAGE_EXAMPLE_SHAPE\n",
    "        \n",
    "        images.append(np_img)\n",
    "        \n",
    "        # horizontal flip both image\n",
    "        horizontal_flipped_img = img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
    "        np_img = np.asarray(img)\n",
    "        images.append(np_img)\n",
    "        \n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee19e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_landmarks(df_metadata) -> np.ndarray:\n",
    "    landmark_examples = []\n",
    "    \n",
    "    for row in df_metadata.iterrows():\n",
    "        single_example = []\n",
    "        flipped_example = []\n",
    "        \n",
    "        for landmark in landmark_columns:\n",
    "            x, y, z = literal_eval(row[1][landmark])\n",
    "            \n",
    "            single_example.extend([x, y, z])\n",
    "            \n",
    "            # horizontal flip landmark\n",
    "            \n",
    "            flipped_example.extend([1-x, y, z])\n",
    "        \n",
    "        landmark_examples.append(np.array(single_example))\n",
    "        landmark_examples.append(np.array(flipped_example))\n",
    "    return np.array(landmark_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48d0a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interleave_np_arrays(a, b):\n",
    "    a_shape = a.shape\n",
    "    c = np.empty((a_shape[0] * 2, a_shape[1]), dtype=a.dtype)\n",
    "    c[0::2] = a\n",
    "    c[1::2] = b\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb567b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "\n",
    "df_train = df_metadata[df_metadata['data_split'] == 'train']\n",
    "X_train_imgs = load_preprocess_imgs([f'{BASE_PATH}{p}' for p in df_train['relative_image_path']])\n",
    "X_train_landmarks = load_preprocess_landmarks(df_train)\n",
    "Y_train = keras.utils.to_categorical([LABEL_TO_ENCODING[l] for l in df_train['label']], 5)\n",
    "Y_train = interleave_np_arrays(Y_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edd439ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 1178, 1178, 1178)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(X_train_imgs), len(X_train_landmarks), len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c46344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load validation data\n",
    "df_val = df_metadata[df_metadata['data_split'] == 'val']\n",
    "X_val_imgs = load_preprocess_imgs([f'{BASE_PATH}{p}' for p in df_val['relative_image_path']])\n",
    "X_val_landmarks = load_preprocess_landmarks(df_val)\n",
    "Y_val = keras.utils.to_categorical([LABEL_TO_ENCODING[l] for l in df_val['label']], 5)\n",
    "Y_val = interleave_np_arrays(Y_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a219056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 200, 200, 200)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val), len(X_val_imgs), len(X_val_landmarks), len(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "641582ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "df_test = df_metadata[df_metadata['data_split'] == 'test']\n",
    "X_test_imgs = load_preprocess_imgs([f'{BASE_PATH}{p}' for p in df_test['relative_image_path']])\n",
    "X_test_landmarks = load_preprocess_landmarks(df_test)\n",
    "Y_test = keras.utils.to_categorical([LABEL_TO_ENCODING[l] for l in df_test['label']], 5)\n",
    "Y_test = interleave_np_arrays(Y_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba59a956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 400, 400, 400)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test), len(X_test_imgs), len(X_test_landmarks), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805e146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b58471a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 360, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_EXAMPLE_SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94dec2",
   "metadata": {},
   "source": [
    "# Define Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e8c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "class ConvGroupLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, channel_size: int, filter_size: Tuple[int, int], dropout_rate: float):\n",
    "        self.conv = Conv2D(channel_size, filter_size, padding='same', kernel_initializer=initializer)\n",
    "        self.max_pool = MaxPooling2D(filter_size)\n",
    "        self.bn = BatchNormalization(axis=-1)\n",
    "        self.relu = LeakyReLU(alpha=0.1)\n",
    "        self.drop_out = Dropout(dropout_rate)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class CNNTower(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_conv_layers:int, initial_channel_size: int, initial_filter_size: Tuple[int, int], dropout_rate: float):\n",
    "        self.initial_conv = Conv2D(initial_channel_size, initial_filter_size, padding='same', kernel_initializer=initializer, input_shape=IMAGE_EXAMPLE_SHAPE)\n",
    "        self.initial_max_pool = MaxPooling2D(initial_filter_size, padding='same')\n",
    "        self.initial_bn = BatchNormalization(axis=-1)\n",
    "        self.initial_relu = LeakyReLU(alpha=0.1)\n",
    "        self.initial_drop_out = Dropout(dropout_rate)\n",
    "        \n",
    "        self.intermediate_conv_layers = []\n",
    "        \n",
    "        for idx in range(num_conv_layers):\n",
    "            channel_size = initial_channel_size//(2**(idx+1))\n",
    "            \n",
    "            self.intermediate_conv_layers.append(ConvGroupLayer(channel_size, initial_filter_size, dropout_rate))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.initial_max_pool(x)\n",
    "        x = self.initial_bn(x)\n",
    "        x = self.initial_relu(x)\n",
    "        x = self.initial_drop_out(x)\n",
    "        \n",
    "        for layer in self.intermediate_conv_layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        return Flatten()(x)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7191764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_tower = CNNTower(num_conv_layers = 3,\n",
    "#                      initial_channel_size = 128,\n",
    "#                      initial_filter_size = (3, 3),\n",
    "#                      dropout_rate = 0.20\n",
    "#                     )\n",
    "# cnn_tower(tf.random.uniform((32, 640, 360, 3), dtype=tf.float32, minval=0, maxval=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c472afb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7742c189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7c631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25045b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbd891bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers: int, initial_dense_size: int, dropout_rate: float):\n",
    "        self.layers = []\n",
    "        \n",
    "        for idx in range(num_layers):\n",
    "            self.layers.append(Dense(initial_dense_size//(2**idx)))\n",
    "            self.layers.append(tf.keras.layers.BatchNormalization())\n",
    "            self.layers.append(LeakyReLU(alpha=0.1))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f182ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn = DNN(3, 256, 0.2)\n",
    "# dnn(tf.random.uniform((32, 488), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e394c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e8894b",
   "metadata": {},
   "source": [
    "# Two Tower Input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3752dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=IMAGE_EXAMPLE_SHAPE)\n",
    "cnn_tower = CNNTower(num_conv_layers = 3,\n",
    "                     initial_channel_size = 128,\n",
    "                     initial_filter_size = (3, 3),\n",
    "                     dropout_rate = 0.20\n",
    "                    )\n",
    "x_cnn_tower = cnn_tower(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4a2761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_input = Input(shape=LANDMARK_EXAMPLE_SHAPE)\n",
    "dnn_tower = DNN(3, 1024, 0.2)\n",
    "\n",
    "x_dnn_tower = dnn_tower(landmark_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45bc6ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = concatenate([x_cnn_tower, x_dnn_tower])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f2f8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tower = DNN(3, 256, 0.2)\n",
    "x = output_tower(x)\n",
    "output = Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6134d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[image_input, landmark_input], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff9e15b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4010ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 640, 360, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 640, 360, 128 3584        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 214, 120, 128 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 214, 120, 128 512         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 214, 120, 128 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 214, 120, 128 0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 214, 120, 64) 73792       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 71, 40, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 71, 40, 64)   256         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 71, 40, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 71, 40, 64)   0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 71, 40, 32)   18464       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 23, 13, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 39)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 23, 13, 32)   128         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         40960       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 23, 13, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024)         4096        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 23, 13, 32)   0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 1024)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 23, 13, 16)   4624        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 4, 16)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 7, 4, 16)     64          max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 7, 4, 16)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 4, 16)     0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 448)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 256)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 704)          0           flatten[0][0]                    \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          180480      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 128)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           8256        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64)           256         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 64)           0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5)            325         leaky_re_lu_9[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,029,429\n",
      "Trainable params: 1,024,469\n",
      "Non-trainable params: 4,960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "638bc9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "188bdc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 17s 470ms/step - loss: 1.4309 - accuracy: 0.5076 - val_loss: 5.1265 - val_accuracy: 0.6800\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 16s 423ms/step - loss: 0.6424 - accuracy: 0.8031 - val_loss: 2.4079 - val_accuracy: 0.6800\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.4403 - accuracy: 0.8565 - val_loss: 1.1978 - val_accuracy: 0.6800\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 15s 412ms/step - loss: 0.3649 - accuracy: 0.8778 - val_loss: 0.6710 - val_accuracy: 0.7100\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.2942 - accuracy: 0.9041 - val_loss: 0.6703 - val_accuracy: 0.6950\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 16s 419ms/step - loss: 0.2590 - accuracy: 0.8913 - val_loss: 0.7464 - val_accuracy: 0.6750\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 15s 418ms/step - loss: 0.2431 - accuracy: 0.9109 - val_loss: 0.6513 - val_accuracy: 0.7200\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1982 - accuracy: 0.9278 - val_loss: 0.7761 - val_accuracy: 0.6800\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1762 - accuracy: 0.9346 - val_loss: 0.6845 - val_accuracy: 0.7200\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.1691 - accuracy: 0.9363 - val_loss: 0.6840 - val_accuracy: 0.7200\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1569 - accuracy: 0.9431 - val_loss: 0.5780 - val_accuracy: 0.7800\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1608 - accuracy: 0.9414 - val_loss: 0.6050 - val_accuracy: 0.7650\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1448 - accuracy: 0.9465 - val_loss: 0.3815 - val_accuracy: 0.8150\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1383 - accuracy: 0.9482 - val_loss: 0.5627 - val_accuracy: 0.7950\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1597 - accuracy: 0.9397 - val_loss: 0.3872 - val_accuracy: 0.8450\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1591 - accuracy: 0.9423 - val_loss: 0.8213 - val_accuracy: 0.7350\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1209 - accuracy: 0.9550 - val_loss: 0.6009 - val_accuracy: 0.7450\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1182 - accuracy: 0.9550 - val_loss: 0.3850 - val_accuracy: 0.8450\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1202 - accuracy: 0.9508 - val_loss: 0.8772 - val_accuracy: 0.7050\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1077 - accuracy: 0.9584 - val_loss: 0.4829 - val_accuracy: 0.8500\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.1041 - accuracy: 0.9728 - val_loss: 0.7543 - val_accuracy: 0.7750\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1150 - accuracy: 0.9584 - val_loss: 0.4524 - val_accuracy: 0.8250\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1038 - accuracy: 0.9601 - val_loss: 0.6740 - val_accuracy: 0.7600\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0890 - accuracy: 0.9686 - val_loss: 1.0271 - val_accuracy: 0.6700\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0869 - accuracy: 0.9720 - val_loss: 0.6691 - val_accuracy: 0.7250\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0931 - accuracy: 0.9677 - val_loss: 0.6274 - val_accuracy: 0.7800\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.1086 - accuracy: 0.9610 - val_loss: 0.4467 - val_accuracy: 0.7750\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.1140 - accuracy: 0.9533 - val_loss: 0.4306 - val_accuracy: 0.8650\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0902 - accuracy: 0.9728 - val_loss: 0.3531 - val_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0734 - accuracy: 0.9754 - val_loss: 0.5268 - val_accuracy: 0.8150\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0760 - accuracy: 0.9703 - val_loss: 0.5361 - val_accuracy: 0.7650\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0999 - accuracy: 0.9643 - val_loss: 0.6147 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0738 - accuracy: 0.9737 - val_loss: 0.6371 - val_accuracy: 0.7900\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0658 - accuracy: 0.9779 - val_loss: 0.3232 - val_accuracy: 0.8550\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0657 - accuracy: 0.9754 - val_loss: 0.6270 - val_accuracy: 0.7850\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0576 - accuracy: 0.9805 - val_loss: 0.4687 - val_accuracy: 0.7800\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0504 - accuracy: 0.9813 - val_loss: 0.3294 - val_accuracy: 0.8450\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0612 - accuracy: 0.9779 - val_loss: 0.4002 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0898 - accuracy: 0.9677 - val_loss: 0.5088 - val_accuracy: 0.7700\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0688 - accuracy: 0.9711 - val_loss: 0.5014 - val_accuracy: 0.8100\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0608 - accuracy: 0.9796 - val_loss: 0.6891 - val_accuracy: 0.7750\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0697 - accuracy: 0.9745 - val_loss: 0.8533 - val_accuracy: 0.8100\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0681 - accuracy: 0.9779 - val_loss: 0.5538 - val_accuracy: 0.7850\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0577 - accuracy: 0.9830 - val_loss: 0.5995 - val_accuracy: 0.7550\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0502 - accuracy: 0.9830 - val_loss: 0.6610 - val_accuracy: 0.8050\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0543 - accuracy: 0.9805 - val_loss: 0.7358 - val_accuracy: 0.7450\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0529 - accuracy: 0.9830 - val_loss: 0.6490 - val_accuracy: 0.7600\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 0.6000 - val_accuracy: 0.8050\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0532 - accuracy: 0.9822 - val_loss: 0.4835 - val_accuracy: 0.7850\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0497 - accuracy: 0.9830 - val_loss: 0.4210 - val_accuracy: 0.8150\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0488 - accuracy: 0.9830 - val_loss: 0.4782 - val_accuracy: 0.8400\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0537 - accuracy: 0.9788 - val_loss: 0.5966 - val_accuracy: 0.8550\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0576 - accuracy: 0.9788 - val_loss: 0.2790 - val_accuracy: 0.8900\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0616 - accuracy: 0.9762 - val_loss: 0.6128 - val_accuracy: 0.8350\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0509 - accuracy: 0.9813 - val_loss: 0.4222 - val_accuracy: 0.8500\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0530 - accuracy: 0.9771 - val_loss: 0.4111 - val_accuracy: 0.8300\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0516 - accuracy: 0.9813 - val_loss: 0.2366 - val_accuracy: 0.9000\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0621 - accuracy: 0.9745 - val_loss: 0.3369 - val_accuracy: 0.8200\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0356 - accuracy: 0.9881 - val_loss: 0.3456 - val_accuracy: 0.9000\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0407 - accuracy: 0.9856 - val_loss: 0.2388 - val_accuracy: 0.8900\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0604 - accuracy: 0.9822 - val_loss: 0.4839 - val_accuracy: 0.8100\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0253 - accuracy: 0.9932 - val_loss: 0.3694 - val_accuracy: 0.8250\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0312 - accuracy: 0.9873 - val_loss: 0.6232 - val_accuracy: 0.8000\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0286 - accuracy: 0.9881 - val_loss: 0.3060 - val_accuracy: 0.8750\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0314 - accuracy: 0.9873 - val_loss: 0.5434 - val_accuracy: 0.8300\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0352 - accuracy: 0.9864 - val_loss: 0.4644 - val_accuracy: 0.8550\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 0.5238 - val_accuracy: 0.8500\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 15s 417ms/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 0.5390 - val_accuracy: 0.8450\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0352 - accuracy: 0.9856 - val_loss: 0.5900 - val_accuracy: 0.8550\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0319 - accuracy: 0.9881 - val_loss: 0.5741 - val_accuracy: 0.8450\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0261 - accuracy: 0.9898 - val_loss: 0.3925 - val_accuracy: 0.8950\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0396 - accuracy: 0.9839 - val_loss: 0.3644 - val_accuracy: 0.8850\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.3484 - val_accuracy: 0.9150\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.3032 - val_accuracy: 0.9100\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0335 - accuracy: 0.9856 - val_loss: 0.7669 - val_accuracy: 0.7950\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0303 - accuracy: 0.9915 - val_loss: 0.4119 - val_accuracy: 0.8800\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0404 - accuracy: 0.9822 - val_loss: 0.5966 - val_accuracy: 0.8600\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0319 - accuracy: 0.9898 - val_loss: 0.7009 - val_accuracy: 0.8200\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0335 - accuracy: 0.9839 - val_loss: 0.3846 - val_accuracy: 0.8850\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.4642 - val_accuracy: 0.8600\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.3372 - val_accuracy: 0.8700\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0351 - accuracy: 0.9847 - val_loss: 0.2904 - val_accuracy: 0.9050\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 0.3940 - val_accuracy: 0.8900\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0493 - accuracy: 0.9864 - val_loss: 0.4783 - val_accuracy: 0.8200\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0458 - accuracy: 0.9847 - val_loss: 0.3631 - val_accuracy: 0.8900\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0388 - accuracy: 0.9864 - val_loss: 0.1914 - val_accuracy: 0.9150\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.3325 - val_accuracy: 0.8750\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.3031 - val_accuracy: 0.9100\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.4646 - val_accuracy: 0.8000\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.4134 - val_accuracy: 0.8250\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0275 - accuracy: 0.9890 - val_loss: 0.3969 - val_accuracy: 0.8300\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.5389 - val_accuracy: 0.8400\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0240 - accuracy: 0.9898 - val_loss: 0.3569 - val_accuracy: 0.8450\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0186 - accuracy: 0.9924 - val_loss: 0.3858 - val_accuracy: 0.8900\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.3018 - val_accuracy: 0.8700\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0322 - accuracy: 0.9881 - val_loss: 0.4915 - val_accuracy: 0.8750\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0318 - accuracy: 0.9898 - val_loss: 0.2560 - val_accuracy: 0.8950\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0220 - accuracy: 0.9907 - val_loss: 0.4638 - val_accuracy: 0.8050\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0227 - accuracy: 0.9907 - val_loss: 0.4052 - val_accuracy: 0.8300\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0262 - accuracy: 0.9907 - val_loss: 0.6244 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9fbe423b90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_imgs, X_train_landmarks], Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "#           callbacks=callbacks,\n",
    "          verbose=1,\n",
    "          validation_data=([X_val_imgs, X_val_landmarks], Y_val),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7896c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 2s 171ms/step - loss: 0.9322 - accuracy: 0.7825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9321689605712891, 0.7825000286102295]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_test_imgs, X_test_landmarks], Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa4e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a556eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds = model.predict([X_test_imgs, X_test_landmarks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aef79a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_labels = np.argmax(Y_test, axis=-1)\n",
    "Y_preds_labels = np.argmax(Y_preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19da35b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86       266\n",
      "           1       0.50      0.06      0.11        32\n",
      "           2       0.87      0.71      0.78        38\n",
      "           3       0.70      0.44      0.54        32\n",
      "           4       0.89      0.50      0.64        32\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.75      0.53      0.59       400\n",
      "weighted avg       0.77      0.78      0.75       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(Y_test_labels, Y_preds_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "796cedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true: List[int], y_pred: List[int], labels=list(LABEL_TO_ENCODING.keys()), ymap=None, figsize=(10,10)):\n",
    "    if ymap is not None:\n",
    "        y_pred = [ymap[yi] for yi in y_pred]\n",
    "        y_true = [ymap[yi] for yi in y_true]\n",
    "        labels = [ymap[yi] for yi in labels]\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax)\n",
    "    # plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6c89644",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_labels_str = [ENCODING_TO_LABEL[l] for l in Y_test_labels]\n",
    "Y_preds_labels_str = [ENCODING_TO_LABEL[l] for l in Y_preds_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6a4af65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix(Y_test_labels_str, Y_preds_labels_str, list(LABEL_TO_ENCODING.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc289e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ccbb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9fe7265",
   "metadata": {},
   "source": [
    "# [Ablation] Image only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5aa8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=IMAGE_EXAMPLE_SHAPE)\n",
    "cnn_tower = CNNTower(num_conv_layers = 3,\n",
    "                     initial_channel_size = 128,\n",
    "                     initial_filter_size = (3, 3),\n",
    "                     dropout_rate = 0.20\n",
    "                    )\n",
    "x_cnn_tower = cnn_tower(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd565205",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tower = DNN(3, 256, 0.2)\n",
    "x = output_tower(x_cnn_tower)\n",
    "output = Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f947b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_model_image = Model(inputs=[image_input], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e1d41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam()\n",
    "\n",
    "ablation_model_image.compile(loss='categorical_crossentropy',\n",
    "                             optimizer=opt,\n",
    "                             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fae7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65ff4943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 16s 421ms/step - loss: 1.1272 - accuracy: 0.5518 - val_loss: 7.3947 - val_accuracy: 0.6800\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.6491 - accuracy: 0.7504 - val_loss: 4.1670 - val_accuracy: 0.6800\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.5068 - accuracy: 0.8048 - val_loss: 1.8176 - val_accuracy: 0.6800\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.4100 - accuracy: 0.8438 - val_loss: 0.5996 - val_accuracy: 0.7900\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.3834 - accuracy: 0.8438 - val_loss: 0.5394 - val_accuracy: 0.7800\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.3206 - accuracy: 0.8667 - val_loss: 0.4395 - val_accuracy: 0.8300\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.2961 - accuracy: 0.8778 - val_loss: 0.4606 - val_accuracy: 0.8600\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.2499 - accuracy: 0.8998 - val_loss: 0.5326 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.2355 - accuracy: 0.9092 - val_loss: 0.5614 - val_accuracy: 0.7800\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.2320 - accuracy: 0.9015 - val_loss: 0.6778 - val_accuracy: 0.7300\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.2056 - accuracy: 0.9185 - val_loss: 0.9112 - val_accuracy: 0.6900\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.2054 - accuracy: 0.9270 - val_loss: 0.7122 - val_accuracy: 0.7800\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1559 - accuracy: 0.9406 - val_loss: 0.6779 - val_accuracy: 0.7700\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1690 - accuracy: 0.9338 - val_loss: 0.7707 - val_accuracy: 0.7600\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1638 - accuracy: 0.9389 - val_loss: 0.5927 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1355 - accuracy: 0.9448 - val_loss: 0.6638 - val_accuracy: 0.7800\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.1400 - accuracy: 0.9474 - val_loss: 0.8591 - val_accuracy: 0.7600\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1466 - accuracy: 0.9491 - val_loss: 0.5390 - val_accuracy: 0.7900\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1285 - accuracy: 0.9491 - val_loss: 0.6676 - val_accuracy: 0.7900\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1114 - accuracy: 0.9703 - val_loss: 0.7036 - val_accuracy: 0.7800\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.1177 - accuracy: 0.9559 - val_loss: 1.0049 - val_accuracy: 0.6900\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1158 - accuracy: 0.9576 - val_loss: 0.9848 - val_accuracy: 0.7100\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1193 - accuracy: 0.9542 - val_loss: 0.9548 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0899 - accuracy: 0.9686 - val_loss: 1.0242 - val_accuracy: 0.7400\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0940 - accuracy: 0.9652 - val_loss: 0.9561 - val_accuracy: 0.7400\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1036 - accuracy: 0.9601 - val_loss: 1.0653 - val_accuracy: 0.7400\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.1021 - accuracy: 0.9593 - val_loss: 0.7862 - val_accuracy: 0.8100\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0756 - accuracy: 0.9728 - val_loss: 0.8573 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0751 - accuracy: 0.9754 - val_loss: 0.5759 - val_accuracy: 0.7900\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0926 - accuracy: 0.9652 - val_loss: 0.7670 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0637 - accuracy: 0.9771 - val_loss: 0.7746 - val_accuracy: 0.7800\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0747 - accuracy: 0.9711 - val_loss: 0.9020 - val_accuracy: 0.7400\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0814 - accuracy: 0.9754 - val_loss: 0.9625 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0741 - accuracy: 0.9745 - val_loss: 0.7946 - val_accuracy: 0.7700\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0639 - accuracy: 0.9779 - val_loss: 0.6307 - val_accuracy: 0.8300\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0630 - accuracy: 0.9796 - val_loss: 0.7513 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0534 - accuracy: 0.9813 - val_loss: 0.7020 - val_accuracy: 0.8300\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0580 - accuracy: 0.9805 - val_loss: 0.6456 - val_accuracy: 0.8200\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0612 - accuracy: 0.9796 - val_loss: 0.6236 - val_accuracy: 0.8300\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0672 - accuracy: 0.9728 - val_loss: 0.6988 - val_accuracy: 0.7800\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0583 - accuracy: 0.9771 - val_loss: 0.8091 - val_accuracy: 0.7700\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0638 - accuracy: 0.9728 - val_loss: 0.8875 - val_accuracy: 0.7000\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0533 - accuracy: 0.9813 - val_loss: 0.5915 - val_accuracy: 0.7700\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0582 - accuracy: 0.9805 - val_loss: 0.6633 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0450 - accuracy: 0.9822 - val_loss: 0.5624 - val_accuracy: 0.8100\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0295 - accuracy: 0.9890 - val_loss: 0.4750 - val_accuracy: 0.8500\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0304 - accuracy: 0.9907 - val_loss: 0.6216 - val_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0611 - accuracy: 0.9779 - val_loss: 0.5836 - val_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0457 - accuracy: 0.9839 - val_loss: 0.5355 - val_accuracy: 0.8400\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0394 - accuracy: 0.9873 - val_loss: 0.7346 - val_accuracy: 0.7900\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0351 - accuracy: 0.9890 - val_loss: 0.8133 - val_accuracy: 0.7800\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0284 - accuracy: 0.9907 - val_loss: 0.6731 - val_accuracy: 0.7900\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0339 - accuracy: 0.9881 - val_loss: 0.7317 - val_accuracy: 0.8400\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 15s 416ms/step - loss: 0.0505 - accuracy: 0.9796 - val_loss: 0.6379 - val_accuracy: 0.8400\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0690 - accuracy: 0.9703 - val_loss: 0.9268 - val_accuracy: 0.7600\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0636 - accuracy: 0.9813 - val_loss: 0.7333 - val_accuracy: 0.8400\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0498 - accuracy: 0.9830 - val_loss: 0.8086 - val_accuracy: 0.8000\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0478 - accuracy: 0.9847 - val_loss: 0.5313 - val_accuracy: 0.8500\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0615 - accuracy: 0.9771 - val_loss: 0.6789 - val_accuracy: 0.8400\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0466 - accuracy: 0.9822 - val_loss: 0.6000 - val_accuracy: 0.8500\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0431 - accuracy: 0.9839 - val_loss: 0.7215 - val_accuracy: 0.8300\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0348 - accuracy: 0.9847 - val_loss: 0.7610 - val_accuracy: 0.8400\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0311 - accuracy: 0.9898 - val_loss: 0.6869 - val_accuracy: 0.8100\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0426 - accuracy: 0.9839 - val_loss: 0.6347 - val_accuracy: 0.8300\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0312 - accuracy: 0.9898 - val_loss: 0.7101 - val_accuracy: 0.8300\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0395 - accuracy: 0.9873 - val_loss: 0.6278 - val_accuracy: 0.8800\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0347 - accuracy: 0.9873 - val_loss: 0.7096 - val_accuracy: 0.8300\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0460 - accuracy: 0.9830 - val_loss: 0.4984 - val_accuracy: 0.8700\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0381 - accuracy: 0.9847 - val_loss: 0.6016 - val_accuracy: 0.8700\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0502 - accuracy: 0.9822 - val_loss: 0.6253 - val_accuracy: 0.8500\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0352 - accuracy: 0.9881 - val_loss: 0.6143 - val_accuracy: 0.8600\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0451 - accuracy: 0.9873 - val_loss: 0.6770 - val_accuracy: 0.8000\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0286 - accuracy: 0.9890 - val_loss: 0.8434 - val_accuracy: 0.8200\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.6094 - val_accuracy: 0.8500\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.6049 - val_accuracy: 0.8700\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0306 - accuracy: 0.9924 - val_loss: 0.5350 - val_accuracy: 0.8700\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0241 - accuracy: 0.9941 - val_loss: 0.6798 - val_accuracy: 0.8800\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0351 - accuracy: 0.9864 - val_loss: 0.6879 - val_accuracy: 0.7900\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0275 - accuracy: 0.9890 - val_loss: 0.5495 - val_accuracy: 0.8600\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0273 - accuracy: 0.9907 - val_loss: 0.6532 - val_accuracy: 0.8600\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0445 - accuracy: 0.9856 - val_loss: 0.6606 - val_accuracy: 0.8600\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0311 - accuracy: 0.9898 - val_loss: 0.5552 - val_accuracy: 0.8500\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0278 - accuracy: 0.9881 - val_loss: 0.5932 - val_accuracy: 0.8400\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0314 - accuracy: 0.9839 - val_loss: 0.5960 - val_accuracy: 0.8300\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.0310 - accuracy: 0.9881 - val_loss: 0.6409 - val_accuracy: 0.8100\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.5846 - val_accuracy: 0.8500\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0334 - accuracy: 0.9864 - val_loss: 0.7252 - val_accuracy: 0.8200\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 0.5054 - val_accuracy: 0.8500\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0376 - accuracy: 0.9873 - val_loss: 0.5697 - val_accuracy: 0.8400\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0426 - accuracy: 0.9839 - val_loss: 0.3831 - val_accuracy: 0.8700\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0335 - accuracy: 0.9873 - val_loss: 0.4379 - val_accuracy: 0.9000\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.5786 - val_accuracy: 0.8700\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 15s 415ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.6726 - val_accuracy: 0.8500\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0291 - accuracy: 0.9898 - val_loss: 0.4494 - val_accuracy: 0.8900\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.7239 - val_accuracy: 0.8300\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.5345 - val_accuracy: 0.8400\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0216 - accuracy: 0.9898 - val_loss: 0.5367 - val_accuracy: 0.8700\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0246 - accuracy: 0.9898 - val_loss: 0.6025 - val_accuracy: 0.8200\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0232 - accuracy: 0.9907 - val_loss: 0.6659 - val_accuracy: 0.8000\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 15s 414ms/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 0.6627 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9fb4503950>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_model_image.fit([X_train_imgs], Y_train,\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=epochs,\n",
    "#                          callbacks=callbacks,\n",
    "                         verbose=1,\n",
    "                         validation_data=([X_val_imgs], Y_val),\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45d39fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds = ablation_model_image.predict([X_test_imgs, X_test_landmarks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50ccf036",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_labels = np.argmax(Y_test, axis=-1)\n",
    "Y_preds_labels = np.argmax(Y_preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c595fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       266\n",
      "           1       0.46      0.38      0.41        32\n",
      "           2       0.75      0.79      0.77        38\n",
      "           3       0.70      0.44      0.54        32\n",
      "           4       0.80      0.25      0.38        32\n",
      "\n",
      "    accuracy                           0.75       400\n",
      "   macro avg       0.70      0.55      0.59       400\n",
      "weighted avg       0.74      0.75      0.73       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(Y_test_labels, Y_preds_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82c7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26ac0b0a",
   "metadata": {},
   "source": [
    "# [Ablation] Pose Landmarks Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87f927b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_input = Input(shape=LANDMARK_EXAMPLE_SHAPE)\n",
    "dnn_tower = DNN(3, 1024, 0.2)\n",
    "\n",
    "x_dnn_tower = dnn_tower(landmark_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f54c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tower = DNN(3, 256, 0.2)\n",
    "x = output_tower(x_dnn_tower)\n",
    "output = Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59e5aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_model_landmark = Model(inputs=[landmark_input], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "074a665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam()\n",
    "\n",
    "ablation_model_landmark.compile(loss='categorical_crossentropy',\n",
    "                                optimizer=opt,\n",
    "                                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8ed23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f59685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 1.2390 - accuracy: 0.5263 - val_loss: 1.3335 - val_accuracy: 0.6700\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.7091 - accuracy: 0.7419 - val_loss: 1.1049 - val_accuracy: 0.6800\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.5279 - accuracy: 0.7988 - val_loss: 1.0908 - val_accuracy: 0.6800\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.5179 - accuracy: 0.7929 - val_loss: 1.0871 - val_accuracy: 0.6800\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.8081 - val_loss: 1.1723 - val_accuracy: 0.6800\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8345 - val_loss: 1.3099 - val_accuracy: 0.6800\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8413 - val_loss: 1.3995 - val_accuracy: 0.5700\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8421 - val_loss: 1.4858 - val_accuracy: 0.5800\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8438 - val_loss: 1.4623 - val_accuracy: 0.6800\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8523 - val_loss: 1.5170 - val_accuracy: 0.4850\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8531 - val_loss: 1.0830 - val_accuracy: 0.6350\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2900 - accuracy: 0.8786 - val_loss: 0.8947 - val_accuracy: 0.7100\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2968 - accuracy: 0.8727 - val_loss: 0.8077 - val_accuracy: 0.7300\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3115 - accuracy: 0.8812 - val_loss: 1.0242 - val_accuracy: 0.6250\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8896 - val_loss: 0.7037 - val_accuracy: 0.7550\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2694 - accuracy: 0.9024 - val_loss: 0.8315 - val_accuracy: 0.6900\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.8769 - val_loss: 1.0120 - val_accuracy: 0.6200\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2773 - accuracy: 0.8786 - val_loss: 0.7088 - val_accuracy: 0.7150\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2382 - accuracy: 0.9075 - val_loss: 0.6352 - val_accuracy: 0.7450\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2353 - accuracy: 0.9151 - val_loss: 0.6018 - val_accuracy: 0.7750\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2343 - accuracy: 0.8973 - val_loss: 0.6527 - val_accuracy: 0.7750\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2155 - accuracy: 0.9151 - val_loss: 0.9484 - val_accuracy: 0.7450\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2432 - accuracy: 0.8973 - val_loss: 0.5326 - val_accuracy: 0.7850\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2122 - accuracy: 0.9168 - val_loss: 0.6559 - val_accuracy: 0.7200\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2284 - accuracy: 0.9066 - val_loss: 0.8166 - val_accuracy: 0.7250\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2025 - accuracy: 0.9295 - val_loss: 0.6578 - val_accuracy: 0.8050\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2054 - accuracy: 0.9160 - val_loss: 0.9973 - val_accuracy: 0.6600\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2031 - accuracy: 0.9117 - val_loss: 0.6086 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1889 - accuracy: 0.9219 - val_loss: 0.6135 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1851 - accuracy: 0.9236 - val_loss: 0.6902 - val_accuracy: 0.7450\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1956 - accuracy: 0.9287 - val_loss: 0.8555 - val_accuracy: 0.6900\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2332 - accuracy: 0.9041 - val_loss: 0.8758 - val_accuracy: 0.6800\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1906 - accuracy: 0.9253 - val_loss: 1.1208 - val_accuracy: 0.5950\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2171 - accuracy: 0.9024 - val_loss: 1.3598 - val_accuracy: 0.5950\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1980 - accuracy: 0.9151 - val_loss: 0.6475 - val_accuracy: 0.7850\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2002 - accuracy: 0.9211 - val_loss: 0.9498 - val_accuracy: 0.7000\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1655 - accuracy: 0.9346 - val_loss: 0.4567 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1703 - accuracy: 0.9355 - val_loss: 0.7601 - val_accuracy: 0.7600\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1933 - accuracy: 0.9219 - val_loss: 0.9822 - val_accuracy: 0.7000\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1563 - accuracy: 0.9389 - val_loss: 0.9066 - val_accuracy: 0.7050\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.9160 - val_loss: 0.6030 - val_accuracy: 0.7750\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1846 - accuracy: 0.9278 - val_loss: 0.6087 - val_accuracy: 0.7800\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.9261 - val_loss: 0.9986 - val_accuracy: 0.7600\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1611 - accuracy: 0.9372 - val_loss: 0.5213 - val_accuracy: 0.8150\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1476 - accuracy: 0.9406 - val_loss: 0.7356 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.9312 - val_loss: 0.9855 - val_accuracy: 0.7200\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1432 - accuracy: 0.9525 - val_loss: 0.5087 - val_accuracy: 0.7950\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1451 - accuracy: 0.9406 - val_loss: 0.8117 - val_accuracy: 0.7250\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9457 - val_loss: 0.5523 - val_accuracy: 0.8550\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1499 - accuracy: 0.9414 - val_loss: 0.6772 - val_accuracy: 0.8350\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1225 - accuracy: 0.9516 - val_loss: 0.7308 - val_accuracy: 0.8150\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1340 - accuracy: 0.9499 - val_loss: 0.7068 - val_accuracy: 0.7750\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1392 - accuracy: 0.9397 - val_loss: 0.7116 - val_accuracy: 0.7900\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9508 - val_loss: 0.8905 - val_accuracy: 0.7550\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1756 - accuracy: 0.9355 - val_loss: 0.7511 - val_accuracy: 0.7050\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1452 - accuracy: 0.9457 - val_loss: 0.5356 - val_accuracy: 0.7950\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1418 - accuracy: 0.9389 - val_loss: 0.6045 - val_accuracy: 0.8250\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9576 - val_loss: 0.5165 - val_accuracy: 0.8350\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1361 - accuracy: 0.9550 - val_loss: 0.4818 - val_accuracy: 0.8750\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.9448 - val_loss: 0.7414 - val_accuracy: 0.7900\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9567 - val_loss: 1.1287 - val_accuracy: 0.7550\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9610 - val_loss: 0.8401 - val_accuracy: 0.7900\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9448 - val_loss: 0.8268 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1483 - accuracy: 0.9457 - val_loss: 0.8351 - val_accuracy: 0.7600\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1409 - accuracy: 0.9482 - val_loss: 0.6483 - val_accuracy: 0.8350\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1383 - accuracy: 0.9448 - val_loss: 0.6930 - val_accuracy: 0.7800\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1338 - accuracy: 0.9491 - val_loss: 1.0592 - val_accuracy: 0.7200\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.9576 - val_loss: 0.8436 - val_accuracy: 0.7600\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1275 - accuracy: 0.9533 - val_loss: 0.8114 - val_accuracy: 0.7900\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1208 - accuracy: 0.9559 - val_loss: 0.7644 - val_accuracy: 0.8000\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.9610 - val_loss: 0.8341 - val_accuracy: 0.8200\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1402 - accuracy: 0.9457 - val_loss: 1.3942 - val_accuracy: 0.7000\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1207 - accuracy: 0.9525 - val_loss: 0.7559 - val_accuracy: 0.8000\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1223 - accuracy: 0.9542 - val_loss: 1.0188 - val_accuracy: 0.7600\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1179 - accuracy: 0.9542 - val_loss: 0.7047 - val_accuracy: 0.7750\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1252 - accuracy: 0.9508 - val_loss: 0.6844 - val_accuracy: 0.7700\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9593 - val_loss: 1.0964 - val_accuracy: 0.7650\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1138 - accuracy: 0.9601 - val_loss: 1.0274 - val_accuracy: 0.7150\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9465 - val_loss: 0.7363 - val_accuracy: 0.8050\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1210 - accuracy: 0.9576 - val_loss: 0.9215 - val_accuracy: 0.7950\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9618 - val_loss: 1.0336 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1363 - accuracy: 0.9508 - val_loss: 0.7890 - val_accuracy: 0.8400\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1734 - accuracy: 0.9389 - val_loss: 1.1383 - val_accuracy: 0.7200\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1128 - accuracy: 0.9584 - val_loss: 0.7654 - val_accuracy: 0.7350\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1099 - accuracy: 0.9593 - val_loss: 0.6207 - val_accuracy: 0.8150\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9610 - val_loss: 0.6795 - val_accuracy: 0.7700\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9584 - val_loss: 0.6879 - val_accuracy: 0.8000\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1232 - accuracy: 0.9542 - val_loss: 0.6968 - val_accuracy: 0.8350\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1112 - accuracy: 0.9610 - val_loss: 0.7512 - val_accuracy: 0.8350\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1172 - accuracy: 0.9550 - val_loss: 0.8645 - val_accuracy: 0.8000\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1257 - accuracy: 0.9584 - val_loss: 0.7614 - val_accuracy: 0.7850\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1260 - accuracy: 0.9508 - val_loss: 0.6592 - val_accuracy: 0.8300\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1201 - accuracy: 0.9516 - val_loss: 0.5986 - val_accuracy: 0.8400\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9686 - val_loss: 0.7284 - val_accuracy: 0.8050\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0761 - accuracy: 0.9694 - val_loss: 0.6940 - val_accuracy: 0.8400\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0988 - accuracy: 0.9643 - val_loss: 0.7952 - val_accuracy: 0.7900\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9694 - val_loss: 0.9524 - val_accuracy: 0.7600\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9745 - val_loss: 1.0509 - val_accuracy: 0.7850\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.9703 - val_loss: 0.7090 - val_accuracy: 0.7650\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.9660 - val_loss: 0.8241 - val_accuracy: 0.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9f64638f90>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_model_landmark.fit([X_train_landmarks], Y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "#                          callbacks=callbacks,\n",
    "                            verbose=1,\n",
    "                            validation_data=([X_val_landmarks], Y_val),\n",
    "                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f88a4845",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds = ablation_model_landmark.predict([X_test_landmarks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39903091",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_labels = np.argmax(Y_test, axis=-1)\n",
    "Y_preds_labels = np.argmax(Y_preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf9f2560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       266\n",
      "           1       0.34      0.31      0.33        32\n",
      "           2       0.80      0.32      0.45        38\n",
      "           3       0.41      0.44      0.42        32\n",
      "           4       0.84      0.97      0.90        32\n",
      "\n",
      "    accuracy                           0.71       400\n",
      "   macro avg       0.63      0.57      0.58       400\n",
      "weighted avg       0.71      0.71      0.70       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(Y_test_labels, Y_preds_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b4e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ec680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edd26d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m69"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
